df_B[[cl]] <- to_char(df_B[[cl]])
}
# Subconjunto nas MESMAS colunas e mesma ordem
common_cols <- c(cols_block, cols_strcmp)
A_use <- df_A[, common_cols]
B_use <- df_B[, common_cols]
# 4) Comparação com blocagem + strcmp ---------------------------------------
rp <- compare.linkage(
A_use, B_use,
blockfld = cols_block,
strcmp   = cols_strcmp
)
cat("\nResumo da comparação (antes dos pesos):\n")
print(summary(rp))
library(dplyr)
library(readr)
library(ggplot2)
# ==== Parâmetros básicos ====
THRESHOLD <- 0.85                                   # corte para aceitar link
LOWER     <- 0.60                                   # zona cinza para revisão
OUT_DIR   <- "3_results/eval_simple"
dir.create(OUT_DIR, showWarnings = FALSE, recursive = TRUE)
# ==== 1) Ler pares ranqueados ====
pairs <- read_csv("3_results/linkage/pairs_ranked.csv", show_col_types = FALSE)
# Se vierem colunas id1/id2 (índices), adapta para id_A/id_B:
if (all(c("id1","id2") %in% names(pairs)) && !all(c("id_A","id_B") %in% names(pairs))) {
pairs <- pairs %>% rename(id_A = id1, id_B = id2)
}
stopifnot(all(c("id_A","id_B","Weight") %in% names(pairs)))
# ==== 2) Top-1 por id_B e decisão por corte ====
top1 <- pairs %>%
group_by(id_B) %>%
slice_max(Weight, n = 1, with_ties = FALSE) %>%
ungroup()
pred_links <- top1 %>% filter(Weight >= THRESHOLD)
gray_review <- top1 %>% filter(Weight >= LOWER, Weight < THRESHOLD)
# ==== 3) Métricas ====
truth <- read_csv("1_raw_data/truth_pairs.csv", show_col_types = FALSE) %>%
mutate(id_A = as.character(id_A), id_B = as.character(id_B))
pred_keys <- paste(pred_links$id_A, pred_links$id_B)
top1_keys <- paste(top1$id_A, top1$id_B)
true_keys <- paste(truth$id_A, truth$id_B)
TP <- sum(pred_keys %in% true_keys)
FP <- nrow(pred_links) - TP
FN <- sum(!(true_keys %in% pred_keys))
TN <- sum(!(top1_keys %in% true_keys) & !(top1_keys %in% pred_keys))
precision <- ifelse(TP+FP == 0, NA, TP/(TP+FP))
recall    <- ifelse(TP+FN == 0, NA, TP/(TP+FN))
f1        <- ifelse(is.na(precision)|is.na(recall)|(precision+recall)==0,
NA, 2*precision*recall/(precision+recall))
tibble(THRESHOLD, TP, FP, FN, TN, precision, recall, f1) %>%
write_csv(file.path(OUT_DIR, "metrics_with_truth.csv"))
# ==== 4) Gráficos====
# Histograma dos scores (top-1)
p1 <- ggplot(top1, aes(Weight)) +
geom_histogram(bins = 40, na.rm = TRUE) +
labs(title = "Distribuição de scores (top-1 por id_B)",
x = "Weight", y = "Contagem")
ggsave(file.path(OUT_DIR, "hist_scores_top1.png"), p1, width = 6.5, height = 4, dpi = 120)
# ==== 5) Salvar saídas principais ====
write_csv(pred_links, file.path(OUT_DIR, "links_final.csv"))     # aceitos (≥ THRESHOLD)
write_csv(gray_review, file.path(OUT_DIR, "review_gray.csv"))    # revisar [LOWER, THRESHOLD)
#------------------GERANDO BASE FINAL
df_A <- read.csv("1_raw_data/dataset_A.csv", stringsAsFactors = FALSE)
df_B <- read.csv("1_raw_data/dataset_B.csv", stringsAsFactors = FALSE)
links_final <- pred_links %>%
dplyr::select(id_A, id_B, Weight) %>%
mutate(decision = "link")
links_final_df <- links_final %>%
dplyr::left_join(df_A, by = "id_A") %>%
dplyr::left_join(df_B, by = "id_B", suffix = c(".A", ".B"))
write.csv(links_final_df,"3_results/links_final.csv", row.names = FALSE)
gray_review <- top1 %>%
dplyr::filter(Weight >= LOWER, Weight < THRESHOLD) %>%
dplyr::mutate(decision = "review_gray") %>%
dplyr::select(id_A, id_B, Weight, decision)
gray_review_df <- gray_review %>%
dplyr::left_join(A, by = "id_A") %>%
dplyr::left_join(B, by = "id_B", suffix = c(".A", ".B"))
write.csv(gray_review_df,"3_results/gray_links_final.csv", row.names = FALSE)
library(dplyr)
library(readr)
library(ggplot2)
# ==== Parâmetros básicos ====
THRESHOLD <- 0.85                                   # corte para aceitar link
LOWER     <- 0.60                                   # zona cinza para revisão
OUT_DIR   <- "3_results/eval_simple"
dir.create(OUT_DIR, showWarnings = FALSE, recursive = TRUE)
# ==== 1) Ler pares ranqueados ====
pairs <- read_csv("3_results/linkage/pairs_ranked.csv", show_col_types = FALSE)
# Se vierem colunas id1/id2 (índices), adapta para id_A/id_B:
if (all(c("id1","id2") %in% names(pairs)) && !all(c("id_A","id_B") %in% names(pairs))) {
pairs <- pairs %>% rename(id_A = id1, id_B = id2)
}
stopifnot(all(c("id_A","id_B","Weight") %in% names(pairs)))
# ==== 2) Top-1 por id_B e decisão por corte ====
top1 <- pairs %>%
group_by(id_B) %>%
slice_max(Weight, n = 1, with_ties = FALSE) %>%
ungroup()
pred_links <- top1 %>% filter(Weight >= THRESHOLD)
gray_review <- top1 %>% filter(Weight >= LOWER, Weight < THRESHOLD)
# ==== 3) Métricas ====
truth <- read_csv("1_raw_data/truth_pairs.csv", show_col_types = FALSE) %>%
mutate(id_A = as.character(id_A), id_B = as.character(id_B))
pred_keys <- paste(pred_links$id_A, pred_links$id_B)
top1_keys <- paste(top1$id_A, top1$id_B)
true_keys <- paste(truth$id_A, truth$id_B)
TP <- sum(pred_keys %in% true_keys)
FP <- nrow(pred_links) - TP
FN <- sum(!(true_keys %in% pred_keys))
TN <- sum(!(top1_keys %in% true_keys) & !(top1_keys %in% pred_keys))
precision <- ifelse(TP+FP == 0, NA, TP/(TP+FP))
recall    <- ifelse(TP+FN == 0, NA, TP/(TP+FN))
f1        <- ifelse(is.na(precision)|is.na(recall)|(precision+recall)==0,
NA, 2*precision*recall/(precision+recall))
tibble(THRESHOLD, TP, FP, FN, TN, precision, recall, f1) %>%
write_csv(file.path(OUT_DIR, "metrics_with_truth.csv"))
# ==== 4) Gráficos====
# Histograma dos scores (top-1)
p1 <- ggplot(top1, aes(Weight)) +
geom_histogram(bins = 40, na.rm = TRUE) +
labs(title = "Distribuição de scores (top-1 por id_B)",
x = "Weight", y = "Contagem")
ggsave(file.path(OUT_DIR, "hist_scores_top1.png"), p1, width = 6.5, height = 4, dpi = 120)
# ==== 5) Salvar saídas principais ====
write_csv(pred_links, file.path(OUT_DIR, "links_final.csv"))     # aceitos (≥ THRESHOLD)
write_csv(gray_review, file.path(OUT_DIR, "review_gray.csv"))    # revisar [LOWER, THRESHOLD)
#------------------GERANDO BASE FINAL
df_A <- read.csv("1_raw_data/dataset_A.csv", stringsAsFactors = FALSE)
df_B <- read.csv("1_raw_data/dataset_B.csv", stringsAsFactors = FALSE)
links_final <- pred_links %>%
dplyr::select(id_A, id_B, Weight) %>%
mutate(decision = "link")
links_final_df <- links_final %>%
dplyr::left_join(df_A, by = "id_A") %>%
dplyr::left_join(df_B, by = "id_B", suffix = c(".A", ".B"))
View(gray_review)
source("~/oficina_linkage/02_linkage_probabilistico.R", echo=TRUE)
library(dplyr)
library(readr)
library(ggplot2)
# ==== Parâmetros básicos ====
THRESHOLD <- 0.85                                   # corte para aceitar link
LOWER     <- 0.77                                   # zona cinza para revisão
OUT_DIR   <- "3_results/eval_simple"
dir.create(OUT_DIR, showWarnings = FALSE, recursive = TRUE)
# ==== 1) Ler pares ranqueados ====
pairs <- read_csv("3_results/linkage/pairs_ranked.csv", show_col_types = FALSE)
links <- read_csv("3_results/linkage/matches_links.csv", show_col_types = FALSE)
sum_lines <- c()
sum_lines <- c(sum_lines, "===== DIAGNÓSTICO GERAL =====")
sum_lines <- c(sum_lines, paste0("Total de pares candidatos: ", nrow(pairs)))
if (!is.null(links)) {
sum_lines <- c(sum_lines, paste0("Total de links decididos: ", nrow(links)))
} else {
sum_lines <- c(sum_lines, "Total de links decididos: (arquivo 'matches_links.csv' não encontrado)")
}
# ==== 2) Top-1 por id_B e decisão por corte ====
top1 <- pairs %>%
group_by(id_B) %>%
slice_max(Weight, n = 1, with_ties = FALSE) %>%
ungroup()
summary_lines <- c()
summary_lines <- c(summary_lines, "===== DIAGNÓSTICO GERAL =====")
summary_lines <- c(summary_lines, paste0("Total de pares candidatos: ", nrow(pairs)))
summary_lines <- c(summary_lines, paste0("Total de links decididos: ", ifelse(is.null(links), 0, nrow(links))))
cat("Total de pares candidatos: ", nrow(pairs))
cat("Total de links decididos: ", nrow(links))
print(summary(pairs$Weight)
print(summary(pairs$Weight))
cat(summary(pairs$Weight))
capture.output(print(summary(pairs$Weight)))
# ---------------------- 4) Amostra p/ clerical review ----------------------
amb <- pairs |>
filter(Weight > LOWER, Weight < THRESHOLD)
clerical_n      <- 50
amostra <- amb |>
slice_sample(n = min(clerical_n, nrow(amb)))
write_csv(amostra, file.path("3_results/linkage/revisao_manual.csv"))
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
THRESHOLD <- 0.85
LOWER     <- 0.77
# ===================== 1) Leitura =====================
pairs <- read_csv("3_results/linkage/pairs_ranked.csv" ,show_col_types = FALSE)
links <- read_csv("3_results/linkage/matches_links.csv", show_col_types = FALSE)
cat("\n===== DIAGNÓSTICO GERAL =====\n")
cat("Total de pares candidatos: ", nrow(pairs), "\n")
cat("Total de links decididos : ", nrow(links), "\n\n")
# ===================== 2) Diagnósticos =====================
cat("Resumo de 'Weight' (pares candidatos):\n")
print(summary(pairs$Weight))
p_hist <- ggplot(pairs, aes(Weight)) +
geom_histogram(bins = 40) +
labs(title = "Distribuição de Weight (pares candidatos)",
x = "Weight", y = "Frequência")
ggsave(file.path(DIR_DIAG, "hist_pesos_pairs.png"),
p_hist, width = 7, height = 5, dpi = 120)
ggsave(file.path(DIR_DIAG, "3_results/hist_pesos_pairs.png"),
p_hist, width = 7, height = 5, dpi = 120)
ggsave(file.path("3_results/hist_pesos_pairs.png"),
p_hist, width = 7, height = 5, dpi = 120)
# ===================== 3) Amostra p/ revisão =====================
ambigua <- pairs %>%
filter(Weight > LOWER, Weight < THRESHOLD)
if (nrow(ambigua) > 0) {
set.seed(123)
clerical_n <- min(50, nrow(ambigua))
amostra <- ambigua %>% slice_sample(n = clerical_n)
write_csv(amostra, file.path(DIR_CLER, "clerical_sample_ambigua.csv"))
cat("\n===== CLERICAL REVIEW =====\n")
cat("Registros na zona ambígua: ", nrow(ambigua),
" | Amostra salva: ", clerical_n, "\n")
} else {
cat("\n===== CLERICAL REVIEW =====\nZona ambígua vazia para os limiares definidos.\n")
}
if (nrow(ambigua) > 0) {
set.seed(123)
clerical_n <- min(50, nrow(ambigua))
amostra <- ambigua %>% slice_sample(n = clerical_n)
write_csv(amostra, file.path("3_results/linkage/revisao_manual.csv"))
cat("Registros na zona ambígua: ", nrow(ambigua),
" | Amostra salva: ", clerical_n, "\n")
} else {
cat(Zona ambígua vazia para os limiares definidos.\n")
if (nrow(ambigua) > 0) {
set.seed(123)
clerical_n <- min(50, nrow(ambigua))
amostra <- ambigua %>% slice_sample(n = clerical_n)
write_csv(amostra, file.path("3_results/linkage/revisao_manual.csv"))
cat("Registros na zona ambígua: ", nrow(ambigua),
" | Amostra salva: ", clerical_n, "\n")
} else {
cat(Zona ambígua vazia para os limiares definidos.\n")
# ===================== 3) Amostra p/ revisão =====================
ambigua <- pairs %>%
filter(Weight > LOWER, Weight < THRESHOLD)
if (nrow(ambigua) > 0) {
set.seed(123)
clerical_n <- min(50, nrow(ambigua))
amostra <- ambigua %>% slice_sample(n = clerical_n)
write_csv(amostra, file.path("3_results/linkage/revisao_manual.csv"))
cat("Registros na zona ambígua: ", nrow(ambigua),
" | Amostra salva: ", clerical_n, "\n")
} else {
cat(Zona ambígua vazia para os limiares definidos.\n") }}
set.seed(123)
if (nrow(ambigua) > 0) {
set.seed(123)
clerical_n <- min(50, nrow(ambigua))
amostra <- ambigua %>% slice_sample(n = clerical_n)
write_csv(amostra, file.path("3_results/linkage/revisao_manual.csv"))
cat("Registros na zona ambígua: ", nrow(ambigua),
" | Amostra salva: ", clerical_n, "\n")
} else { cat(Zona ambígua vazia para os limiares definidos.\n") }
clerical_n <- min(50, nrow(ambigua))
amostra <- ambigua %>% slice_sample(n = clerical_n)
write_csv(amostra,"3_results/linkage/revisao_manual.csv")
# ===================== 4) Métricas (com gabarito) =====================
make_keys_recid <- function(df) paste0(as.character(df$RecID1), "||", as.character(df$RecID2))
metrics <- NULL
if (file.exists(truth_path)) {
truth <- read_csv(truth_path, show_col_types = FALSE)
# Aceita gabarito com (id_A, id_B) OU (RecID1, RecID2).
if (all(c("id_A","id_B") %in% names(truth))) {
# Caso o seu gabarito use IDs próprios (id_A/id_B), você precisará
# mapear esses IDs para as posições/índices (RecID1/RecID2).
# Para manter o script simples e didático, **recomenda-se**
# fornecer o gabarito já no formato RecID1/RecID2.
stop("Gabarito com colunas id_A/id_B detectado.\n",
"Para este script simples, forneça 'truth_pairs.csv' com 'RecID1' e 'RecID2'.")
}
if (!all(c("RecID1","RecID2") %in% names(truth))) {
stop("O gabarito deve conter colunas 'RecID1' e 'RecID2'.")
}
true_keys <- unique(make_keys_recid(truth))
pred_keys <- if (nrow(links) > 0) unique(make_keys_recid(links)) else character(0)
cand_keys <- unique(make_keys_recid(pairs))  # universo para TN (opcional)
TP <- sum(pred_keys %in% true_keys)
FP <- length(pred_keys) - TP
FN <- sum(!(true_keys %in% pred_keys))
TN <- sum(!(cand_keys %in% true_keys) & !(cand_keys %in% pred_keys))  # opcional
precision <- ifelse(TP + FP == 0, NA_real_, TP / (TP + FP))
recall    <- ifelse(TP + FN == 0, NA_real_, TP / (TP + FN))
f1        <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0,
NA_real_, 2 * precision * recall / (precision + recall))
metrics <- tibble::tibble(
threshold_used = THRESHOLD,
TP, FP, FN, TN,
precision, recall, f1
)
write_csv(metrics, file.path(DIR_DIAG, "metrics_with_truth.csv"))
cat("\n===== MÉTRICAS (com gabarito) =====\n")
print(metrics)
} else {
cat("\nSem gabarito em '", truth_path, "'. Pulando métricas supervisionadas.\n", sep = "")
}
truth_path <- "1_raw_data/truth_pairs.csv"
truth <- read_csv(truth_path, show_col_types = FALSE)
true_keys <- unique(make_keys_recid(truth))
# ===================== 4) Métricas (com gabarito) =====================
make_keys_recid <- function(df) paste0(as.character(df$id1), "||", as.character(df$id2))
true_keys <- unique(make_keys_recid(truth))
# ===================== 4) Métricas (com gabarito) =====================
make_keys_recid <- function(df) paste0(as.character(df$id_A), "||", as.character(df$id_B))
true_keys <- unique(make_keys_recid(truth))
pred_keys <- if (nrow(links) > 0) unique(make_keys_recid(links)) else character(0)
# ===================== 4) Métricas (com gabarito) =====================
pred_keys <- paste(links$id1, links$id2)
true_keys <- paste(truth$id_A, truth$id_B)
TP <- sum(pred_keys %in% true_keys)
FP <- length(pred_keys) - TP
FN <- sum(!true_keys %in% pred_keys)
if (file.exists("3_results/linkage/pairs_ranked.csv")) {
cand <- read.csv("3_results/linkage/pairs_ranked.csv", stringsAsFactors = FALSE)
cand_keys <- paste(cand$id1, cand$id2)
TN <- sum(!(cand_keys %in% true_keys) & !(cand_keys %in% pred_keys))
} else TN <- NA_integer_
precision <- ifelse(TP+FP==0, NA, TP/(TP+FP))
recall    <- ifelse(TP+FN==0, NA, TP/(TP+FN))
f1        <- ifelse(is.na(precision)|is.na(recall)|(precision+recall)==0, NA, 2*precision*recall/(precision+recall))
metrics <- data.frame(THRESHOLD=0.85, TP, FP, FN, TN, precision, recall, f1)
write.csv(metrics, "3_results/metrics_with_truth.csv", row.names = FALSE)
print(metrics)
}
# ===================== 5) Saídas finais (join com bases) =====================
# Aqui vamos montar duas tabelas:
# - links_final.csv       -> todos os links aceitos (>= THRESHOLD), com dados de A e B
# - gray_links_final.csv  -> pares na zona ambígua, com dados de A e B (para revisão)
#
# Base A/B usadas: as mesmas do passo 02 (pré-processadas)
A <- read.csv("2_refined_data/dataset_A_pre.csv", stringsAsFactors = FALSE)
B <- read.csv("2_refined_data/dataset_B_pre.csv", stringsAsFactors = FALSE)
A$A_idx <- seq_len(nrow(A))
B$B_idx <- seq_len(nrow(B))
# ---- Links aceitos (matches_links.csv) ----
if (nrow(links) > 0) {
links_final <- links %>%
transmute(RecID1 = as.integer(RecID1),
RecID2 = as.integer(RecID2),
Weight = if ("Weight" %in% names(links)) Weight else NA_real_,
decision = "link") %>%
left_join(A, by = c("RecID1" = "A_idx")) %>%
left_join(B, by = c("RecID2" = "B_idx"),
suffix = c(".A", ".B"))
write.csv(links_final, file.path(DIR_FINAL, "links_final.csv"), row.names = FALSE)
cat("\nlinks_final.csv salvo em ", file.path(DIR_FINAL, "links_final.csv"), "\n", sep = "")
} else {
cat("\nNenhum link aceito para salvar em links_final.csv.\n")
}
# ---- Links aceitos (matches_links.csv) ----
if (nrow(links) > 0) {
links_final <- links %>%
transmute(id1 = as.integer(id1),
id2 = as.integer(id2),
Weight = if ("Weight" %in% names(links)) Weight else NA_real_,
decision = "link") %>%
left_join(A, by = c("id1" = "A_idx")) %>%
left_join(B, by = c("id2" = "B_idx"),
suffix = c(".A", ".B"))
write.csv(links_final, file.path(DIR_FINAL, "links_final.csv"), row.names = FALSE)
cat("\nlinks_final.csv salvo em ", file.path(DIR_FINAL, "links_final.csv"), "\n", sep = "")
} else {
cat("\nNenhum link aceito para salvar em links_final.csv.\n")
}
# ---- Links aceitos (matches_links.csv) ----
if (nrow(links) > 0) {
links_final <- links %>%
transmute(id1 = as.integer(id1),
id2 = as.integer(id2),
Weight = if ("Weight" %in% names(links)) Weight else NA_real_,
decision = "link") %>%
left_join(A, by = c("id1" = "A_idx")) %>%
left_join(B, by = c("id2" = "B_idx"),
suffix = c(".A", ".B"))
write.csv(links_final,"3_results/links_final.csv", row.names = FALSE)
}
# ---- Zona cinza (ambígua) ----
if (nrow(ambigua) > 0) {
gray_links_final <- ambigua %>%
transmute(RecID1 = as.integer(id1),
RecID2 = as.integer(id2),
Weight,
decision = "review_gray") %>%
left_join(A, by = c("id1" = "A_idx")) %>%
left_join(B, by = c("id2" = "B_idx"),
suffix = c(".A", ".B"))
write.csv(gray_links_final, file.path(DIR_FINAL, "gray_links_final.csv"), row.names = FALSE)
}
# ---- Zona cinza (ambígua) ----
if (nrow(ambigua) > 0) {
gray_links_final <- ambigua %>%
transmute(id1 = as.integer(id1),
id2 = as.integer(id2),
Weight,
decision = "review_gray") %>%
left_join(A, by = c("id1" = "A_idx")) %>%
left_join(B, by = c("id2" = "B_idx"),
suffix = c(".A", ".B"))
write.csv(gray_links_final, file.path(DIR_FINAL, "gray_links_final.csv"), row.names = FALSE)
}
# ---- Zona cinza (ambígua) ----
if (nrow(ambigua) > 0) {
gray_links_final <- ambigua %>%
transmute(id1 = as.integer(id1),
id2 = as.integer(id2),
Weight,
decision = "review_gray") %>%
left_join(A, by = c("id1" = "A_idx")) %>%
left_join(B, by = c("id2" = "B_idx"),
suffix = c(".A", ".B"))
write.csv(gray_links_final, "gray_links_final.csv"), row.names = FALSE)
# ---- Zona cinza (ambígua) ----
if (nrow(ambigua) > 0) {
gray_links_final <- ambigua %>%
transmute(id1 = as.integer(id1),
id2 = as.integer(id2),
Weight,
decision = "review_gray") %>%
left_join(A, by = c("id1" = "A_idx")) %>%
left_join(B, by = c("id2" = "B_idx"),
suffix = c(".A", ".B"))
write.csv(gray_links_final, "gray_links_final.csv", row.names = FALSE)
}
library(fakelink)
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
THRESHOLD <- 0.85
LOWER     <- 0.77
truth <- read_csv("1_raw_data/truth_pairs.csv",show_col_types = FALSE)
# ===================== 1) Leitura =====================
pairs <- read_csv("3_results/linkage/pairs_ranked.csv" ,show_col_types = FALSE)
links <- read_csv("3_results/linkage/matches_links.csv", show_col_types = FALSE)
cat("\n===== DIAGNÓSTICO GERAL =====\n")
cat("Total de pares candidatos: ", nrow(pairs), "\n")
# ===================== 1) Leitura =====================
pairs <- read_csv("3_results/linkage/pairs_ranked.csv" ,show_col_types = FALSE)
links <- read_csv("3_results/linkage/matches_links.csv", show_col_types = FALSE)
cat("\n===== DIAGNÓSTICO GERAL =====\n")
cat("Total de pares candidatos: ", nrow(pairs), "\n")
cat("Total de links decididos : ", nrow(links), "\n\n")
# ===================== 2) Diagnósticos =====================
cat("Resumo de 'Weight' (pares candidatos):\n")
print(summary(pairs$Weight))
p_hist <- ggplot(pairs, aes(Weight)) +
geom_histogram(bins = 40) +
labs(title = "Distribuição de Weight (pares candidatos)",
x = "Weight", y = "Frequência")
ggsave(file.path("3_results/hist_pesos_pairs.png"),
p_hist, width = 7, height = 5, dpi = 120)
# ===================== 3) Amostra p/ revisão =====================
ambigua <- pairs %>%
filter(Weight > LOWER, Weight < THRESHOLD)
clerical_n <- min(50, nrow(ambigua))
amostra <- ambigua %>% slice_sample(n = clerical_n)
write_csv(amostra,"3_results/linkage/revisao_manual.csv")
# ===================== 4) Métricas (com gabarito) =====================
pred_keys <- paste(links$id1, links$id2)
true_keys <- paste(truth$id_A, truth$id_B)
TP <- sum(pred_keys %in% true_keys)
FP <- length(pred_keys) - TP
FN <- sum(!true_keys %in% pred_keys)
if (file.exists("3_results/linkage/pairs_ranked.csv")) {
cand <- read.csv("3_results/linkage/pairs_ranked.csv", stringsAsFactors = FALSE)
cand_keys <- paste(cand$id1, cand$id2)
TN <- sum(!(cand_keys %in% true_keys) & !(cand_keys %in% pred_keys))
} else TN <- NA_integer_
precision <- ifelse(TP+FP==0, NA, TP/(TP+FP))
recall    <- ifelse(TP+FN==0, NA, TP/(TP+FN))
f1        <- ifelse(is.na(precision)|is.na(recall)|(precision+recall)==0, NA, 2*precision*recall/(precision+recall))
metrics <- data.frame(THRESHOLD=0.85, TP, FP, FN, TN, precision, recall, f1)
write.csv(metrics, "3_results/metrics_with_truth.csv", row.names = FALSE)
print(metrics)
# ===================== 5) Saídas finais (join com bases) =====================
# Aqui vamos montar duas tabelas:
# - links_final.csv       -> todos os links aceitos (>= THRESHOLD), com dados de A e B
# - gray_links_final.csv  -> pares na zona ambígua, com dados de A e B (para revisão)
#
# Base A/B usadas: as mesmas do passo 02 (pré-processadas)
A <- read.csv("2_refined_data/dataset_A_pre.csv", stringsAsFactors = FALSE)
B <- read.csv("2_refined_data/dataset_B_pre.csv", stringsAsFactors = FALSE)
A$A_idx <- seq_len(nrow(A))
B$B_idx <- seq_len(nrow(B))
# ---- Links aceitos (matches_links.csv) ----
if (nrow(links) > 0) {
links_final <- links %>%
transmute(id1 = as.integer(id1),
id2 = as.integer(id2),
Weight = if ("Weight" %in% names(links)) Weight else NA_real_,
decision = "link") %>%
left_join(A, by = c("id1" = "A_idx")) %>%
left_join(B, by = c("id2" = "B_idx"),
suffix = c(".A", ".B"))
write.csv(links_final,"3_results/links_final.csv", row.names = FALSE)
}
# ---- Zona cinza (ambígua) ----
if (nrow(ambigua) > 0) {
gray_links_final <- ambigua %>%
transmute(id1 = as.integer(id1),
id2 = as.integer(id2),
Weight,
decision = "review_gray") %>%
left_join(A, by = c("id1" = "A_idx")) %>%
left_join(B, by = c("id2" = "B_idx"),
suffix = c(".A", ".B"))
write.csv(gray_links_final, "gray_links_final.csv", row.names = FALSE)
}
