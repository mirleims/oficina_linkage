library(ggplot2)
library(pROC)   # para ROC/AUC
PAIRS_F   <- "3_results/linkage/pairs_ranked.csv"  # candidatos + Weight
TRUTH_F   <- "1_raw_data/truth_pairs.csv"          # id_A,id_B (opcional)
THRESHOLD <- 0.85                                  # ajuste seu corte
OUT_DIR   <- "3_results/eval_simple"
dir.create(OUT_DIR, showWarnings = FALSE, recursive = TRUE)
pairs <- read_csv(PAIRS_F, show_col_types = FALSE)
pairs <- pairs %>% dplyr::rename(id_A = id1, id_B = id2)
# top-1 por id_B (decisão única por registro B)
top1 <- pairs %>%
group_by(id_B) %>% slice_max(Weight, n = 1, with_ties = FALSE) %>% ungroup()
pred_links <- top1 %>% filter(Weight >= THRESHOLD)
# COM PARES VERDADEIROS -------------------------------------------
#-----------------
truth <- read_csv(TRUTH_F, show_col_types = FALSE)
true_keys <- paste(truth$id_A, truth$id_B, sep = "_")
pred_keys <- paste(pred_links$id_A, pred_links$id_B, sep = "_")
top1_keys <- paste(top1$id_A, top1$id_B, sep = "_")
TP <- sum(pred_keys %in% true_keys)
FP <- nrow(pred_links) - TP
FN <- sum(!(true_keys %in% pred_keys))
TN <- sum(!(top1_keys %in% true_keys) & !(top1_keys %in% pred_keys))  # negativos corretos no universo top-1
precision <- ifelse(TP+FP==0, NA, TP/(TP+FP))
recall    <- ifelse(TP+FN==0, NA, TP/(TP+FN))
f1        <- ifelse(is.na(precision)|is.na(recall)|(precision+recall)==0, NA, 2*precision*recall/(precision+recall))
tibble::tibble(THRESHOLD, TP, FP, FN, TN, precision, recall, f1) %>%
readr::write_csv(file.path(OUT_DIR, "metrics_with_truth.csv"))
#------------------------------------Histogramas: score e gap (top1 – top2)
# --- Histograma de scores (top-1 por id_B) ---------------------------------
p_scores <- ggplot(top1, aes(x = Weight)) +
geom_histogram(bins = 40, na.rm = TRUE) +
labs(title = "Distribuição de scores (top-1 por id_B)",
x = "Weight", y = "Contagem")
ggsave(file.path(OUT_DIR, "hist_scores_top1.png"),
plot = p_scores, width = 6.5, height = 4, dpi = 120)
# --- Gap top1 - top2 -------------------------------------------------------
top2 <- pairs %>%
dplyr::group_by(id_B) %>%
dplyr::slice_max(Weight, n = 2, with_ties = FALSE) %>%
dplyr::ungroup() %>%
dplyr::group_by(id_B) %>%
dplyr::summarise(
top1 = dplyr::first(sort(Weight, decreasing = TRUE)),
top2 = ifelse(dplyr::n() >= 2, sort(Weight, decreasing = TRUE)[2], NA_real_),
gap  = top1 - top2,
.groups = "drop"
)
p_gap <- ggplot(top2, aes(x = gap)) +
geom_histogram(bins = 40, na.rm = TRUE) +
labs(title = "Separação top1 - top2 (maiores gaps = decisão mais fácil)",
x = "gap (top1 - top2)", y = "Contagem")
ggsave(file.path(OUT_DIR, "hist_gap_top1_top2.png"),
plot = p_gap, width = 6.5, height = 4, dpi = 120)
#---------------CURVA ROC
y_true <- (top1_keys %in% true_keys) * 1L
roc_top1 <- roc(response = y_true, predictor = top1$Weight, direction = ">")
roc_df <- tibble::tibble(
TPR = roc_top1$sensitivities,
FPR = 1 - roc_top1$specificities
)
ggplot(roc_df, aes(FPR, TPR)) +
geom_path() + geom_abline(slope = 1, intercept = 0, linetype = 2) +
labs(title = paste0("ROC (top-1) — AUC = ", round(as.numeric(auc(roc_top1)), 4)),
x = "FPR (1 - Especificidade)", y = "TPR (Recall)") +
ggsave(file.path(OUT_DIR, "roc_top1.png"), width = 6, height = 5, dpi = 120)
#------------------GERANDO BASE FINAL
df_A <- read.csv("1_raw_data/dataset_A.csv", stringsAsFactors = FALSE)
df_B <- read.csv("1_raw_data/dataset_B.csv", stringsAsFactors = FALSE)
LOWER <- 0.85   # opcional: faixa de revisão [LOWER, THRESHOLD)
links_final <- pred_links %>%
dplyr::select(id_A, id_B, Weight) %>%
mutate(decision = "link")
links_final
links_final_wide <- links_final %>%
dplyr::left_join(A, by = "id_A") %>%
dplyr::left_join(B, by = "id_B", suffix = c(".A", ".B"))
links_final_wide <- links_final %>%
dplyr::left_join(df_A, by = "id_A") %>%
dplyr::left_join(df_B, by = "id_B", suffix = c(".A", ".B"))
links_final_wide
write.csv(links_final_df,"3_results/links_final.csv", row.names = FALSE)
links_final_df <- links_final %>%
dplyr::left_join(df_A, by = "id_A") %>%
dplyr::left_join(df_B, by = "id_B", suffix = c(".A", ".B"))
write.csv(links_final_df,"3_results/links_final.csv", row.names = FALSE)
# ---------------------------------------------------------
# Carregando os pacotes
library(janitor)  # limpeza e checagem de dados
library(stringr)  # manipulação de string
library(abjutils) # normalizar texto (ex.: remover acentos)
# ----------------------------
# 1) Carregar dados
# ---------------------------
dir.create("2_refined_data", showWarnings = FALSE, recursive = TRUE)
dir.create("3_results", showWarnings = FALSE, recursive = TRUE)
dir.create("3_results/linkage", showWarnings = FALSE, recursive = TRUE)
df_A <- read.csv("1_raw_data/dataset_A.csv", stringsAsFactors = FALSE)
df_B <- read.csv("1_raw_data/dataset_B.csv", stringsAsFactors = FALSE)
# Visualização das colunas de cada dataset
cat("Colunas dataset A: ", names(df_A))
cat("Colunas dataset B: ", names(df_B))
message("Prévia A:"); print(utils::head(df_A[, c("nome","nome_mae","data_nascimento","municipio")], 5))
message("Prévia B:"); print(utils::head(df_B[, c("nome","nome_mae","data_nascimento","municipio")], 5))
# Campos mínimos esperados:
req_cols <- c("nome", "nome_mae", "data_nascimento", "municipio")
miss_A <- setdiff(req_cols, names(df_A))
miss_B <- setdiff(req_cols, names(df_B))
if (length(miss_A) > 0) stop("Base A faltando colunas: ", paste(miss_A, collapse = ", "))
if (length(miss_B) > 0) stop("Base B faltando colunas: ", paste(miss_B, collapse = ", "))
# 2.1) Harmonização dos dados
harmonizacao <- function(x, rm_stopwords = FALSE) {
x <- as.character(x)
# remover acentos: abjutils -> stringi -> iconv
if (requireNamespace("abjutils", quietly = TRUE)) {
x <- abjutils::rm_accent(x)
} else if (requireNamespace("stringi", quietly = TRUE)) {
x <- stringi::stri_trans_general(x, "Latin-ASCII")
} else {
x <- iconv(x, to = "ASCII//TRANSLIT")
}
# caixa alta
x <- toupper(x)
# remover pontuação (mantém A–Z, 0–9 e espaço)
x <- stringr::str_replace_all(x, "[^A-Z0-9 ]", " ")
# remoção de espaços
x <- stringr::str_squish(x)
# remover preposições comuns (útil para blocking por município/nome)
if (isTRUE(rm_stopwords)) {
x <- stringr::str_replace_all(x, "\\b(DO|DA|DOS|DAS|DE|DI|DU)\\b", " ")
x <- stringr::str_squish(x)  }
#retorna o vetor limpo
x
}
# 2.2) Datas: conversão tentando formatos comuns
parse_date_safe <- function(x) {
x <- as.character(x)
# tenta ISO (YYYY-MM-DD) / default
d <- suppressWarnings(as.Date(x))
# tenta BR (DD/MM/YYYY)
idx <- is.na(d) & grepl("^\\d{2}/\\d{2}/\\d{4}$", x)
if (any(idx)) d[idx] <- as.Date(x[idx], format = "%d/%m/%Y")
# tenta US (MM/DD/YYYY)
idx <- is.na(d) & grepl("^\\d{2}/\\d{2}/\\d{4}$", x)
if (any(idx)) d[idx] <- as.Date(x[idx], format = "%m/%d/%Y")
d   }
# Faça backup dos originais (didático, para comparação futura):
df_A$nome_original      <- df_A$nome
df_A$nome_mae_original  <- df_A$nome_mae
df_B$nome_original      <- df_B$nome
df_B$nome_mae_original  <- df_B$nome_mae
# Normalização textual (sem remover pontuação por padrão)
df_A$nome     <- harmonizacao(df_A$nome)
df_A$nome_mae <- harmonizacao(df_A$nome_mae)
df_B$nome     <- harmonizacao(df_B$nome)
df_B$nome_mae <- harmonizacao(df_B$nome_mae)
# Datas como Date (com parse)
df_A$data_nascimento <- parse_date_safe(df_A$data_nascimento)
df_B$data_nascimento <- parse_date_safe(df_B$data_nascimento)
# município normalizado (aqui aproveitamos para remover preposições)
df_A$municipio_blk <- harmonizacao(df_A$municipio, rm_stopwords = TRUE)
df_B$municipio_blk <- harmonizacao(df_B$municipio, rm_stopwords = TRUE)
# ano de nascimento (como texto, útil para blocking)
df_A$ano_nasc <- format(df_A$data_nascimento, "%Y")
df_B$ano_nasc <- format(df_B$data_nascimento, "%Y")
# ----------------------------------------------------
# 5) Diagnóstico rápido
# ----------------------------------------------------
message("Prévia A:"); print(utils::head(df_A[, c("nome","nome_mae","data_nascimento","municipio_blk","ano_nasc")], 5))
message("Prévia B:"); print(utils::head(df_B[, c("nome","nome_mae","data_nascimento","municipio_blk","ano_nasc")], 5))
# ----------------------------------------------------
# 6) Salvar versões preprocessadas
# ----------------------------------------------------
write.csv(df_A, "2_refined_data/dataset_A_pre.csv", row.names = FALSE)
write.csv(df_B, "2_refined_data/dataset_B_pre.csv", row.names = FALSE)
message("Pré-processamento concluído.")
library(RecordLinkage)
library(dplyr)
# 1) Leitura -----------------------------------------------------------------
df_A <- read.csv("2_refined_data/dataset_A_pre.csv", stringsAsFactors = FALSE)
df_B <- read.csv("2_refined_data/dataset_B_pre.csv", stringsAsFactors = FALSE)
# 2) Definir campos para blocagem e comparação -------------------------------
cols_block  <- c("municipio_blk", "ano_nasc")                  # blocagem
cols_strcmp <- c("nome", "nome_mae", "data_nascimento")        # comparação aproximada
# Checagem de colunas
miss_A <- setdiff(c(cols_block, cols_strcmp), names(df_A))
miss_B <- setdiff(c(cols_block, cols_strcmp), names(df_B))
if (length(miss_A) > 0) stop("Base A faltando colunas: ", paste(miss_A, collapse = ", "))
if (length(miss_B) > 0) stop("Base B faltando colunas: ", paste(miss_B, collapse = ", "))
# 3) Harmonizar tipos ---------------
to_char <- function(v) {
if (inherits(v, "Date")) return(format(v, "%Y-%m-%d"))
as.character(v)
}
for (cl in c(cols_block, cols_strcmp)) {
df_A[[cl]] <- to_char(df_A[[cl]])
df_B[[cl]] <- to_char(df_B[[cl]])
}
# Subconjunto nas MESMAS colunas e mesma ordem
common_cols <- c(cols_block, cols_strcmp)
A_use <- df_A[, common_cols]
B_use <- df_B[, common_cols]
# 4) Comparação com blocagem + strcmp ---------------------------------------
rp <- compare.linkage(
A_use, B_use,
blockfld = cols_block,
strcmp   = cols_strcmp
)
cat("\nResumo da comparação (antes dos pesos):\n")
print(summary(rp))
# 5) Pesos, pares e classificação -------------------------------------------
rp <- epiWeights(rp)
# Pares (todos candidatos), ordena por peso
pairs_tbl <- getPairs(rp, single.rows = TRUE)
if (!is.null(pairs_tbl) && nrow(pairs_tbl) > 0) {
pairs_tbl <- pairs_tbl[order(-pairs_tbl$Weight), ]
write.csv(pairs_tbl, "3_results/linkage/pairs_ranked.csv", row.names = FALSE)
} else {
warning("getPairs(rp) retornou 0 linhas (nenhum candidato).")
write.csv(data.frame(), "3_results/linkage/pairs_ranked.csv", row.names = FALSE)
}
# Classificação por limiares
threshold_upper <- 0.85
threshold_lower <- 0.60
rp <- epiClassify(rp, threshold.upper = threshold_upper, threshold.lower = threshold_lower)
cat("\nResumo após classificação por limiares:\n")
print(summary(rp))
# 6) LINKS  ----------------------------------
# Primeiro tenta com o argumento 'show = "links"'.
links_tbl <- tryCatch(
getPairs(rp, single.rows = TRUE, show = "links"),
error = function(e) NULL
)
# Fallback: filtra manualmente via rp$prediction
if (is.null(links_tbl)) {
pairs_all <- getPairs(rp, single.rows = TRUE)
pred <- rp$prediction
# normaliza 'prediction' (pode ser lógico, numérico, fator ou char)
if (is.factor(pred))    pred <- as.character(pred)
if (is.logical(pred)) {
idx <- pred
} else if (is.numeric(pred)) {
idx <- (pred == 1)
} else {
idx <- tolower(pred) %in% c("l","link","links","match","m","1","true","matched")
}
links_tbl <- pairs_all[idx, , drop = FALSE]
}
# Exporta links (vazio se não houver)
if (!is.null(links_tbl) && nrow(links_tbl) > 0) {
write.csv(links_tbl, "3_results/linkage/matches_links.csv", row.names = FALSE)
} else {
warning("Nenhum link classificado acima do limiar. Arquivo salvo vazio.")
write.csv(data.frame(),"3_results/linkage/matches_links.csv", row.names = FALSE)
}
library(dplyr)
library(readr)
library(ggplot2)
library(pROC)   # para ROC/AUC
PAIRS_F   <- "3_results/linkage/pairs_ranked.csv"  # candidatos + Weight
TRUTH_F   <- "1_raw_data/truth_pairs.csv"          # id_A,id_B (opcional)
THRESHOLD <- 0.85                                  # ajuste seu corte
OUT_DIR   <- "3_results/eval_simple"
dir.create(OUT_DIR, showWarnings = FALSE, recursive = TRUE)
pairs <- read_csv(PAIRS_F, show_col_types = FALSE)
pairs <- pairs %>% dplyr::rename(id_A = id1, id_B = id2)
# top-1 por id_B (decisão única por registro B)
top1 <- pairs %>%
group_by(id_B) %>% slice_max(Weight, n = 1, with_ties = FALSE) %>% ungroup()
pred_links <- top1 %>% filter(Weight >= THRESHOLD)
truth <- read_csv(TRUTH_F, show_col_types = FALSE)
true_keys <- paste(truth$id_A, truth$id_B, sep = "_")
pred_keys <- paste(pred_links$id_A, pred_links$id_B, sep = "_")
top1_keys <- paste(top1$id_A, top1$id_B, sep = "_")
TP <- sum(pred_keys %in% true_keys)
FP <- nrow(pred_links) - TP
FN <- sum(!(true_keys %in% pred_keys))
TN <- sum(!(top1_keys %in% true_keys) & !(top1_keys %in% pred_keys))  # negativos corretos no universo top-1
precision <- ifelse(TP+FP==0, NA, TP/(TP+FP))
recall    <- ifelse(TP+FN==0, NA, TP/(TP+FN))
f1        <- ifelse(is.na(precision)|is.na(recall)|(precision+recall)==0, NA, 2*precision*recall/(precision+recall))
tibble::tibble(THRESHOLD, TP, FP, FN, TN, precision, recall, f1) %>%
readr::write_csv(file.path(OUT_DIR, "metrics_with_truth.csv"))
#------------------------------------Histogramas: score e gap (top1 – top2)
# --- Histograma de scores (top-1 por id_B) ---------------------------------
p_scores <- ggplot(top1, aes(x = Weight)) +
geom_histogram(bins = 40, na.rm = TRUE) +
labs(title = "Distribuição de scores (top-1 por id_B)",
x = "Weight", y = "Contagem")
ggsave(file.path(OUT_DIR, "hist_scores_top1.png"),
plot = p_scores, width = 6.5, height = 4, dpi = 120)
# --- Gap top1 - top2 -------------------------------------------------------
top2 <- pairs %>%
dplyr::group_by(id_B) %>%
dplyr::slice_max(Weight, n = 2, with_ties = FALSE) %>%
dplyr::ungroup() %>%
dplyr::group_by(id_B) %>%
dplyr::summarise(
top1 = dplyr::first(sort(Weight, decreasing = TRUE)),
top2 = ifelse(dplyr::n() >= 2, sort(Weight, decreasing = TRUE)[2], NA_real_),
gap  = top1 - top2,
.groups = "drop"
)
p_gap <- ggplot(top2, aes(x = gap)) +
geom_histogram(bins = 40, na.rm = TRUE) +
labs(title = "Separação top1 - top2 (maiores gaps = decisão mais fácil)",
x = "gap (top1 - top2)", y = "Contagem")
ggsave(file.path(OUT_DIR, "hist_gap_top1_top2.png"),
plot = p_gap, width = 6.5, height = 4, dpi = 120)
#---------------CURVA ROC
y_true <- (top1_keys %in% true_keys) * 1L
roc_top1 <- roc(response = y_true, predictor = top1$Weight, direction = ">")
roc_df <- tibble::tibble(
TPR = roc_top1$sensitivities,
FPR = 1 - roc_top1$specificities
)
ggplot(roc_df, aes(FPR, TPR)) +
geom_path() + geom_abline(slope = 1, intercept = 0, linetype = 2) +
labs(title = paste0("ROC (top-1) — AUC = ", round(as.numeric(auc(roc_top1)), 4)),
x = "FPR (1 - Especificidade)", y = "TPR (Recall)") +
ggsave(file.path(OUT_DIR, "roc_top1.png"), width = 6, height = 5, dpi = 120)
library(dplyr)
library(readr)
library(ggplot2)
# ==== Parâmetros básicos ====
THRESHOLD <- 0.85                                   # corte para aceitar link
LOWER     <- 0.75                                   # zona cinza para revisão
OUT_DIR   <- "3_results/eval_simple"
dir.create(OUT_DIR, showWarnings = FALSE, recursive = TRUE)
# ==== 1) Ler pares ranqueados ====
pairs <- read_csv("3_results/linkage/pairs_ranked.csv", show_col_types = FALSE)
# Se vierem colunas id1/id2 (índices), adapta para id_A/id_B:
if (all(c("id1","id2") %in% names(pairs)) && !all(c("id_A","id_B") %in% names(pairs))) {
pairs <- pairs %>% rename(id_A = id1, id_B = id2)
}
library(RecordLinkage)
library(dplyr)
# 1) Leitura -----------------------------------------------------------------
df_A <- read.csv("2_refined_data/dataset_A_pre.csv", stringsAsFactors = FALSE)
df_B <- read.csv("2_refined_data/dataset_B_pre.csv", stringsAsFactors = FALSE)
# 2) Definir campos para blocagem e comparação -------------------------------
cols_block  <- c("municipio_blk", "ano_nasc")                  # blocagem
cols_strcmp <- c("nome", "nome_mae", "data_nascimento")        # comparação aproximada
# Checagem de colunas
miss_A <- setdiff(c(cols_block, cols_strcmp), names(df_A))
miss_B <- setdiff(c(cols_block, cols_strcmp), names(df_B))
if (length(miss_A) > 0) stop("Base A faltando colunas: ", paste(miss_A, collapse = ", "))
# 3) Harmonizar tipos ---------------
to_char <- function(v) {
if (inherits(v, "Date")) return(format(v, "%Y-%m-%d"))
as.character(v)
}
for (cl in c(cols_block, cols_strcmp)) {
df_A[[cl]] <- to_char(df_A[[cl]])
df_B[[cl]] <- to_char(df_B[[cl]])
}
# Subconjunto nas MESMAS colunas e mesma ordem
common_cols <- c(cols_block, cols_strcmp)
A_use <- df_A[, common_cols]
B_use <- df_B[, common_cols]
# 4) Comparação com blocagem + strcmp ---------------------------------------
rp <- compare.linkage(
df_A, df_B,
blockfld = cols_block,
strcmp   = cols_strcmp
)
cat("\nResumo da comparação (antes dos pesos):\n")
print(summary(rp))
# 5) Pesos, pares e classificação -------------------------------------------
rp <- epiWeights(rp)
# Pares (todos candidatos), ordena por peso
pairs_tbl <- getPairs(rp, single.rows = TRUE)
if (!is.null(pairs_tbl) && nrow(pairs_tbl) > 0) {
pairs_tbl <- pairs_tbl[order(-pairs_tbl$Weight), ]
write.csv(pairs_tbl, "3_results/linkage/pairs_ranked.csv", row.names = FALSE)
} else {
warning("getPairs(rp) retornou 0 linhas (nenhum candidato).")
write.csv(data.frame(), "3_results/linkage/pairs_ranked.csv", row.names = FALSE)
}
# Classificação por limiares
threshold_upper <- 0.85
threshold_lower <- 0.60
rp <- epiClassify(rp, threshold.upper = threshold_upper, threshold.lower = threshold_lower)
cat("\nResumo após classificação por limiares:\n")
print(summary(rp))
# 4) Comparação com blocagem + strcmp ---------------------------------------
rp <- compare.linkage(
A_use, B_use,
blockfld = cols_block,
strcmp   = cols_strcmp
)
cat("\nResumo da comparação (antes dos pesos):\n")
print(summary(rp))
# 5) Pesos, pares e classificação -------------------------------------------
rp <- epiWeights(rp)
# Pares (todos candidatos), ordena por peso
pairs_tbl <- getPairs(rp, single.rows = TRUE)
if (!is.null(pairs_tbl) && nrow(pairs_tbl) > 0) {
pairs_tbl <- pairs_tbl[order(-pairs_tbl$Weight), ]
write.csv(pairs_tbl, "3_results/linkage/pairs_ranked.csv", row.names = FALSE)
} else {
warning("getPairs(rp) retornou 0 linhas (nenhum candidato).")
write.csv(data.frame(), "3_results/linkage/pairs_ranked.csv", row.names = FALSE)
}
# Classificação por limiares
threshold_upper <- 0.85
threshold_lower <- 0.60
rp <- epiClassify(rp, threshold.upper = threshold_upper, threshold.lower = threshold_lower)
cat("\nResumo após classificação por limiares:\n")
print(summary(rp))
# 6) LINKS  ----------------------------------
# Primeiro tenta com o argumento 'show = "links"'.
links_tbl <- tryCatch(
getPairs(rp, single.rows = TRUE, show = "links"),
error = function(e) NULL
)
# Fallback: filtra manualmente via rp$prediction
if (is.null(links_tbl)) {
pairs_all <- getPairs(rp, single.rows = TRUE)
pred <- rp$prediction
# normaliza 'prediction' (pode ser lógico, numérico, fator ou char)
if (is.factor(pred))    pred <- as.character(pred)
if (is.logical(pred)) {
idx <- pred
} else if (is.numeric(pred)) {
idx <- (pred == 1)
} else {
idx <- tolower(pred) %in% c("l","link","links","match","m","1","true","matched")
}
links_tbl <- pairs_all[idx, , drop = FALSE]
}
write.csv(links_tbl, "3_results/linkage/matches_links.csv", row.names = FALSE)
message("✔ Comparação concluída.")
library(dplyr)
library(readr)
library(ggplot2)
# ==== Parâmetros básicos ====
THRESHOLD <- 0.85                                   # corte para aceitar link
LOWER     <- 0.60                                   # zona cinza para revisão
OUT_DIR   <- "3_results/eval_simple"
dir.create(OUT_DIR, showWarnings = FALSE, recursive = TRUE)
# ==== 1) Ler pares ranqueados ====
pairs <- read_csv("3_results/linkage/pairs_ranked.csv", show_col_types = FALSE)
# Se vierem colunas id1/id2 (índices), adapta para id_A/id_B:
if (all(c("id1","id2") %in% names(pairs)) && !all(c("id_A","id_B") %in% names(pairs))) {
pairs <- pairs %>% rename(id_A = id1, id_B = id2)
}
stopifnot(all(c("id_A","id_B","Weight") %in% names(pairs)))
# ==== 2) Top-1 por id_B e decisão por corte ====
top1 <- pairs %>%
group_by(id_B) %>%
slice_max(Weight, n = 1, with_ties = FALSE) %>%
ungroup()
pred_links <- top1 %>% filter(Weight >= THRESHOLD)
gray_review <- top1 %>% filter(Weight >= LOWER, Weight < THRESHOLD)
# ==== 3) Métricas ====
truth <- read_csv("1_raw_data/truth_pairs.csv", show_col_types = FALSE) %>%
mutate(id_A = as.character(id_A), id_B = as.character(id_B))
pred_keys <- paste(pred_links$id_A, pred_links$id_B)
top1_keys <- paste(top1$id_A, top1$id_B)
true_keys <- paste(truth$id_A, truth$id_B)
TP <- sum(pred_keys %in% true_keys)
FP <- nrow(pred_links) - TP
FN <- sum(!(true_keys %in% pred_keys))
TN <- sum(!(top1_keys %in% true_keys) & !(top1_keys %in% pred_keys))
precision <- ifelse(TP+FP == 0, NA, TP/(TP+FP))
recall    <- ifelse(TP+FN == 0, NA, TP/(TP+FN))
f1        <- ifelse(is.na(precision)|is.na(recall)|(precision+recall)==0,
NA, 2*precision*recall/(precision+recall))
tibble(THRESHOLD, TP, FP, FN, TN, precision, recall, f1) %>%
write_csv(file.path(OUT_DIR, "metrics_with_truth.csv"))
# ==== 4) Gráficos====
# Histograma dos scores (top-1)
p1 <- ggplot(top1, aes(Weight)) +
geom_histogram(bins = 40, na.rm = TRUE) +
labs(title = "Distribuição de scores (top-1 por id_B)",
x = "Weight", y = "Contagem")
ggsave(file.path(OUT_DIR, "hist_scores_top1.png"), p1, width = 6.5, height = 4, dpi = 120)
# Histograma do GAP top1-top2 (ajuda a ver separação)
top2 <- pairs %>%
group_by(id_B) %>% slice_max(Weight, n = 2, with_ties = FALSE) %>%
arrange(id_B, desc(Weight)) %>%
summarise(top1 = first(Weight),
top2 = ifelse(n() >= 2, nth(Weight, 2), NA_real_),
gap = top1 - top2, .groups = "drop")
p2 <- ggplot(top2, aes(gap)) +
geom_histogram(bins = 40, na.rm = TRUE) +
labs(title = "GAP (top1 - top2) por id_B",
x = "gap", y = "Contagem")
ggsave(file.path(OUT_DIR, "hist_gap_top1_top2.png"), p2, width = 6.5, height = 4, dpi = 120)
# ==== 5) Salvar saídas principais ====
write_csv(pred_links, file.path(OUT_DIR, "links_final.csv"))     # aceitos (≥ THRESHOLD)
write_csv(gray_review, file.path(OUT_DIR, "review_gray.csv"))    # revisar [LOWER, THRESHOLD)
#------------------GERANDO BASE FINAL
df_A <- read.csv("1_raw_data/dataset_A.csv", stringsAsFactors = FALSE)
df_B <- read.csv("1_raw_data/dataset_B.csv", stringsAsFactors = FALSE)
links_final <- pred_links %>%
dplyr::select(id_A, id_B, Weight) %>%
mutate(decision = "link")
links_final_df <- links_final %>%
dplyr::left_join(df_A, by = "id_A") %>%
dplyr::left_join(df_B, by = "id_B", suffix = c(".A", ".B"))
write.csv(links_final_df,"3_results/links_final.csv", row.names = FALSE)
LOWER <- 0.75
gray_review <- top1 %>%
dplyr::filter(Weight >= LOWER, Weight < THRESHOLD) %>%
dplyr::mutate(decision = "review_gray") %>%
dplyr::select(id_A, id_B, Weight, decision)
gray_review_df <- gray_review %>%
dplyr::left_join(A, by = "id_A") %>%
dplyr::left_join(B, by = "id_B", suffix = c(".A", ".B"))
write.csv(gray_review_df,"3_results/gray_links_final.csv", row.names = FALSE)
